{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "anime_df = pd.read_csv('anime.csv')  # Update the file path as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "anime_df.fillna('', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12294 entries, 0 to 12293\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   anime_id  12294 non-null  int64 \n",
      " 1   name      12294 non-null  object\n",
      " 2   genre     12294 non-null  object\n",
      " 3   type      12294 non-null  object\n",
      " 4   episodes  12294 non-null  object\n",
      " 5   rating    12294 non-null  object\n",
      " 6   members   12294 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 672.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(anime_df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert episodes and rating to numeric \n",
    "anime_df['episodes'] = pd.to_numeric(anime_df['episodes'], errors='coerce')\n",
    "anime_df['rating'] = pd.to_numeric(anime_df['rating'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_id      0\n",
      "name          0\n",
      "genre         0\n",
      "type          0\n",
      "episodes    340\n",
      "rating      230\n",
      "members       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(anime_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "anime_df.dropna(subset=['episodes', 'rating'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "anime_df['type'] = label_encoder.fit_transform(anime_df['type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the genres and use a one-hot encoding approach\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Split genres into lists\n",
    "anime_df['genre'] = anime_df['genre'].apply(lambda x: x.split(', ') if x != '' else [])\n",
    "\n",
    "# Apply MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = pd.DataFrame(mlb.fit_transform(anime_df['genre']), columns=mlb.classes_, index=anime_df.index)\n",
    "\n",
    "# Concatenate the encoded genre DataFrame with the original DataFrame\n",
    "anime_df = pd.concat([anime_df, genre_encoded], axis=1)\n",
    "anime_df.drop('genre', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>...</th>\n",
       "      <th>Shounen Ai</th>\n",
       "      <th>Slice of Life</th>\n",
       "      <th>Space</th>\n",
       "      <th>Sports</th>\n",
       "      <th>Super Power</th>\n",
       "      <th>Supernatural</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Vampire</th>\n",
       "      <th>Yaoi</th>\n",
       "      <th>Yuri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name  type  episodes  rating  \\\n",
       "0     32281                    Kimi no Na wa.     0       1.0    9.37   \n",
       "1      5114  Fullmetal Alchemist: Brotherhood     5      64.0    9.26   \n",
       "2     28977                          Gintama°     5      51.0    9.25   \n",
       "3      9253                       Steins;Gate     5      24.0    9.17   \n",
       "4      9969                     Gintama&#039;     5      51.0    9.16   \n",
       "\n",
       "   members  Action  Adventure  Cars  Comedy  ...  Shounen Ai  Slice of Life  \\\n",
       "0   200630       0          0     0       0  ...           0              0   \n",
       "1   793665       1          1     0       0  ...           0              0   \n",
       "2   114262       1          0     0       1  ...           0              0   \n",
       "3   673572       0          0     0       0  ...           0              0   \n",
       "4   151266       1          0     0       1  ...           0              0   \n",
       "\n",
       "   Space  Sports  Super Power  Supernatural  Thriller  Vampire  Yaoi  Yuri  \n",
       "0      0       0            0             1         0        0     0     0  \n",
       "1      0       0            0             0         0        0     0     0  \n",
       "2      0       0            0             0         0        0     0     0  \n",
       "3      0       0            0             0         1        0     0     0  \n",
       "4      0       0            0             0         0        0     0     0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() \n",
    "anime_df[['episodes', 'rating', 'members']] = scaler.fit_transform(anime_df[['episodes', 'rating', 'members']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Features to use for similarity\n",
    "features = ['type', 'episodes', 'rating', 'members'] + list(mlb.classes_)\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(anime_df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim, threshold=0.2): #try to change threshold \n",
    "    # Check if the title exists in anime_df\n",
    "    if title not in anime_df['name'].values:\n",
    "        raise ValueError(f\"Title '{title}' not found in the dataset.\")\n",
    "    \n",
    "    idx_list = anime_df.index[anime_df['name'] == title].tolist()\n",
    "    if not idx_list:\n",
    "        raise ValueError(f\"Index for title '{title}' not found.\")\n",
    "    \n",
    "    idx = idx_list[0]\n",
    "\n",
    "    # Check for index bounds\n",
    "    if idx >= cosine_sim.shape[0]:\n",
    "        raise IndexError(f\"Index {idx} out of bounds for cosine_sim of shape {cosine_sim.shape}\")\n",
    "    \n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = [score for score in sim_scores if score[1] > threshold]\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "    return anime_df['name'].iloc[anime_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_recommendations(test_data, cosine_sim, threshold=0.1):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for idx, row in test_data.iterrows():\n",
    "        true_anime = row['name']\n",
    "        recommendations = get_recommendations(true_anime, cosine_sim=cosine_sim, threshold=threshold)\n",
    "        \n",
    "        for anime in recommendations:\n",
    "            true_labels.append(true_anime)\n",
    "            predicted_labels.append(anime)\n",
    "\n",
    "    true_labels = [1] * len(true_labels)\n",
    "    predicted_labels = [1 if pred in test_data['name'].values else 0 for pred in predicted_labels]\n",
    "    \n",
    "    precision = precision_score(true_labels, predicted_labels, average='micro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='micro')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='micro')\n",
    "    \n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_df.reset_index(drop=True, inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(anime_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime_df size: 11876\n",
      "cosine_sim shape: (11876, 11876)\n"
     ]
    }
   ],
   "source": [
    "print(f\"anime_df size: {anime_df.shape[0]}\")\n",
    "print(f\"cosine_sim shape: {cosine_sim.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example recommendation for 'Naruto':\n",
      "2445                 Naruto Shippuuden: Sunny Side Battle\n",
      "1098    Boruto: Naruto the Movie - Naruto ga Hokage ni...\n",
      "174                                Katekyo Hitman Reborn!\n",
      "7583                              Kyutai Panic Adventure!\n",
      "1336                                          Naruto x UT\n",
      "580                                                Bleach\n",
      "205                                         Dragon Ball Z\n",
      "177                                 Boku no Hero Academia\n",
      "586                                       Dragon Ball Kai\n",
      "2601                                           Medaka Box\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example recommendation for 'Naruto':\")\n",
    "print(get_recommendations('Naruto', cosine_sim=cosine_sim, threshold=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.19452861952861952\n",
      "Recall: 0.19452861952861952\n",
      "F1-score: 0.19452861952861952\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1 = evaluate_recommendations(test_data, cosine_sim, threshold=0.1)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Can you explain the difference between user-based and item-based collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering is a technique used in recommendation systems where the system makes recommendations based on the past behavior of users or items. The main idea is that users who have similar preferences in the past will have similar preferences in the future.\n",
    "\n",
    "User-Based Collaborative Filtering:\n",
    "\n",
    "In user-based collaborative filtering, the system finds users that are similar to the target user based on their historical interactions or preferences (e.g., ratings).\n",
    "It then recommends items that these similar users liked, assuming that if users liked the same items in the past, they will like similar items in the future.\n",
    "Example: If User A and User B have rated movies similarly, then the movies that User B liked but User A has not yet seen will be recommended to User A.\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simple and intuitive.\n",
    "Works well when you have a good amount of user data.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Can suffer from the cold start problem (difficulty recommending for new users or new items with little data).\n",
    "It can be computationally expensive for large datasets because it requires comparing the target user with every other user in the system.\n",
    "\n",
    "Item-Based Collaborative Filtering:\n",
    "\n",
    "In item-based collaborative filtering, the system looks for items that are similar to the ones the target user has already interacted with.\n",
    "Instead of finding similar users, it finds items that have been rated similarly by users and recommends those items.\n",
    "Example: If User A likes Movie X, the system will recommend other movies that have been liked by users who also liked Movie X, even if those users have different preferences.\n",
    "\n",
    "Pros:\n",
    "\n",
    "It is more scalable than user-based filtering because item similarities don’t change often.\n",
    "It works better when there is more item interaction data than user interaction data.\n",
    "\n",
    "Cons:\n",
    "\n",
    "It can struggle with recommending new or rare items (the cold start problem for items).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What is collaborative filtering, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering is a popular technique used in recommendation systems, where recommendations are made based on the historical interactions of users or items. The core idea is that if users have agreed on liking certain items in the past, they will likely agree in the future as well.\n",
    "\n",
    "There are two primary types of collaborative filtering:\n",
    "\n",
    "Memory-Based Collaborative Filtering:\n",
    "\n",
    "In this approach, the system uses the entire dataset of user-item interactions to make predictions. It computes similarities between users or items using metrics like cosine similarity, Pearson correlation, or Euclidean distance.\n",
    "User-Based Memory Filtering: Finds similar users and recommends items based on those.\n",
    "Item-Based Memory Filtering: Finds similar items and recommends them to users who have already interacted with a given item.\n",
    "Example: If User A and User B have similar ratings for certain movies, the system will recommend to User A the movies that User B has rated highly but User A has not yet seen.\n",
    "\n",
    "Model-Based Collaborative Filtering:\n",
    "\n",
    "In this approach, the system creates a predictive model based on the user-item interaction matrix. This model is used to predict ratings or preferences.\n",
    "Techniques include Matrix Factorization (e.g., Singular Value Decomposition or SVD), Neural Networks, or Factorization Machines.\n",
    "The model is trained on historical data to learn latent factors (hidden features) that explain user-item interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
